\documentclass[conference]{IEEEtran}

% Required packages
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{listings}
\usepackage{float}
\usepackage{hyperref}
\usepackage{booktabs} % Added for better table formatting

% Hyperlink setup
\hypersetup{
  colorlinks=true,
  linkcolor=black, % IEEE uses black for print compatibility
  urlcolor=blue,
  citecolor=black
}

% Listing setup for code blocks
\lstset{
  basicstyle=\ttfamily\small, % Slightly larger font for single column readability
  breaklines=true,
  columns=fullflexible,
  frame=single,
  showstringspaces=false,
  captionpos=b
}

% Title and Author setup
\title{Thalassa: Finance ML Project}

\author{\IEEEauthorblockN{Nishat Ahmad}
\IEEEauthorblockA{\textit{Reg No # 2023574} \\
\textit{Tech Stack: Python 3.11, FastAPI, Prefect, Docker, GitHub Actions}\\
\today}
}

\begin{document}

\maketitle

% Abstract
\begin{abstract}
This project addresses the gap in financial machine learning by implementing an automated, end-to-end ML system that turns a manual workflow into a repeatable MLOps pipeline. The system ingests market data using \texttt{yfinance} with retries and timeouts; engineers time-series features (rolling statistics, momentum indicators, lags); trains multiple models (classification, regression, forecasting) and unsupervised modules (PCA, KMeans); and produces versioned artifacts (models, metadata, and diagnostics) and exposes them through an API.
\end{abstract}

\begin{IEEEkeywords}
Finance ML, MLOps, Time Series, Automation, Docker
\end{IEEEkeywords}

\section{Introduction \& Problem Statement}
Financial time series are noisy, non-stationary, and influenced by stochastic shocks (macro events, liquidity regimes, and sentiment). In practice, teams often begin with notebooks that download data, compute features, train a model, and visually inspect results [1], [2]. While effective for exploration, notebook-driven workflows are difficult to reproduce, hard to validate systematically, and fragile to operationalize (changing dependencies, inconsistent data snapshots, and manual re-runs).

The core problem statement is: \textit{How can we reliably train, validate, version, and serve financial ML models on continually drifting market data without relying on manual, error-prone notebook execution?}

\section{ML Experiments \& Comparison}
Thalassa runs multiple ML tasks in one orchestration flow, enabling side-by-side experimentation.

\subsection{Prediction (Supervised Learning)}
\begin{itemize}
    \item \textbf{XGBoost Regression (Return Prediction)}
    The system employs Gradient Boosted Decision Trees (XGBoost) to predict the next-day fractional return by building an ensemble of regression trees that sequentially fit the residuals of prior trees. This model was selected because it prevents overfitting better than simpler linear models. The prediction target is defined as the next-day return, also  the input matrix comprises engineered numeric features. To prevent look-ahead bias, the data is split chronologically into an 80\% training set and a 20\% hold-out test set, with the model minimizing squared error loss subject to regularization parameters like a 0.05 learning rate, a maximum depth of 4, and 0.8 subsampling. Post-training, the metadata is serialized in the versioned registry, allowing the inference engine to align incoming data to the stored feature order and generate forward-looking forecasts using the latest available row. [3].
    \item \textbf{XGBoost Classifier (Directional Prediction)}
    The system utilizes an XGBoost Classifier to predict the directional movement (Up/Down) of the asset by optimizing a binary logistic objective. This model was chosen because it can detect complex, non-straightforward market patterns and provides reliable probability estimates (e.g., '70\% chance of going up') rather than just simple Yes/No predictions. The target is constructed as a binary label based on the sign of the next-day return ($y > 0$), utilizing the same engineered feature set as the regression task. Data is split chronologically into 80\% training and 20\% validation sets. Key hyperparameters include a learning rate of 0.1, a maximum depth of 5, and 0.8 subsampling to maintain generalization. Final artifacts, e.g. calibration metadata, are serialized in the registry to ensure consistent inference on new data.
\end{itemize}

\subsection{Forecasting (Time Series)}
\begin{itemize}
  \item \textbf{ARIMA Forecast (Price Trajectory)}
    The system applies an Autoregressive Integrated Moving Average (ARIMA) model to generate multi-step forecasts of the asset's closing price. This model was chosen because it serves as a reliable standard for comparison and, unlike complex AI models that hide their math, it provides clear 'best case' and 'worst case' price ranges to show how uncertain the future prediction is. It looks only at the history of the Closing price itself. Before running, it fills in any missing data (like holidays) to ensure a smooth timeline, and it stabilizes the trend—making it easier to predict—by looking at day-to-day price changes rather than raw dollar amounts. A default order of $(1,1,1)$ is employed to balance autoregressive trends with moving average error correction, with parameters estimated via maximum likelihood. Final artifacts, including point predictions for a 7-day horizon, confidence bounds, and diagnostics (AIC/BIC), are serialized in the registry to support risk assessment and visual analysis [4].
\end{itemize}

\subsection{Clustering \& Representation Learning (Unsupervised)}
\begin{itemize}
    \item \textbf{Principal Component Analysis}
    The system employs Principal Component Analysis (PCA) to compress the high-dimensional engineered feature set into a compact low-dimensional embedding. This technique was chosen because it simplifies the mess of around a 2 dozen of noisy market features into just a few key signals, making it much easier to spot patterns. The pipeline first standardizes inputs to ensure equal weighting across diverse features (e.g., Price vs. RSI), then performs singular value decomposition to identify orthogonal components. The resulting embeddings and scaler parameters are serialized in the registry, serving as the foundational input for the content-based recommendation engine (Nearest Neighbors) and downstream cluster analysis.
    \item \textbf{K-Means Clustering}
    The system implements K-Means clustering to partition the diverse history of market data into distinct behavioral groups. This method was chosen because it automatically organizes thousands of messy trading days into a few clear "regimes"—such as "stable growth" or "chaotic volatility"—without requiring manual labeling, simply by grouping days that look statistically similar.  The pipeline operates on the standardized feature set, with a default value of $k=5$ clusters. The final cluster centers and labels are serialized in the registry, enabling the system to instantly classify new market conditions by mapping them to these established historical patterns.[5].
    \item \textbf{Apriori Algorithm}
    The system employs the Apriori algorithm to discover hidden relationships between different market indicators.  This method was selected because it acts like a "market detective," automatically generating simple "if-then" rules (e.g., "If Volume is High AND Price is rising, THEN the trend usually continues") that reveal how different signals trigger one another, rather than just predicting a final number. To do this, the pipeline first converts continuous numerical data into binary tags—such as "High Volume" or "Price Above Average"—and then iteratively scans the history to find combinations that occur frequently. The resulting high-confidence rules are filtered by their statistical strength (lift) and serialized in the registry, providing a readable list of historical probabilities that can be used to validate trading strategies.
\end{itemize}

\begin{table}[htbp]
\caption{Model Technical Metrics Summary}
\label{tab:model-registry}
\begin{center}

% \resizebox forces the table to fit exactly within the current column width
\resizebox{\columnwidth}{!}{%
\renewcommand{\arraystretch}{1.4} % Adds vertical padding
\begin{tabular}{|l|p{2.5cm}|c|p{2.2cm}|p{4.5cm}|}
\hline
\textbf{Model} & \textbf{Used for} & \textbf{Feat.} & \textbf{Metrics} & \textbf{Hyperparameters (settings)} \\
\hline
\textbf{XGB Regressor} & Next-day return forecasting & 26 & RMSE; MAE & n\_estimators=300, max\_depth=4, learning\_rate=0.05, random\_state=42; time split 80/20 chronological \\
\hline
\textbf{XGB Classifier} & Next-day direction (up/down) classification & 26 & AUC; Logloss & objective=binary:logistic, max\_depth=5, subsample=0.8, seed=42, early\_stopping\_rounds=10 \\
\hline
\textbf{ARIMA Forecast} & Close-price forecasting for a fixed horizon & N/A & Residual RMSE; MAE; AIC; BIC & order=(1,1,1); horizon default 7 \\
\hline
\textbf{PCA Embedding} & Dimensionality reduction & 27 & Cumulative explained variance & n\_components=5) \\
\hline
\textbf{KMeans Clustering} & Regime/behavior clustering over feature vectors & 27 & Inertia; label counts & n\_clusters=5, random\_state=42 \\
\hline
\textbf{Association Rules} & Pattern mining on derived boolean data & N/A & n\_rules; support confidence lift & min\_support=0.05, min\_confidence=0.5, max\_rules=100 \\
\hline
\end{tabular}%
}
\end{center}
\end{table}

\subsection{Comparison Guidance}
In finance, the ``best'' model is often task-dependent:
\begin{itemize}
  \item For trading-like binary decisions, AUC summarizes ranking ability while Logloss reflects probability quality; calibration metrics help quantify reliability.
  \item For continuous return modeling, RMSE/MAE measure error magnitude but must be interpreted in the context of return scale and regime volatility.
  \item For forecasting, ARIMA offers interpretability and strong baselines; AIC/BIC help compare fit quality.
  \item For exploratory structure, PCA and KMeans help detect latent factors and market regimes, serving both analysis and feature compression.
\end{itemize}

\section{System Architecture}
Thalassa is designed as a modular system that separates orchestration, serving, and artifact persistence [6].

\begin{figure}[htbp]
  \centering
  % Make sure the filename inside {} matches exactly what you uploaded
  \includegraphics[width=1\linewidth]{system_arch.png}
  \caption{High-level system architecture of Thalassa. The FastAPI service serves predictions/forecasts and can trigger the Prefect pipeline. Prefect Server coordinates runs, while the worker executes ETL + training. Artifacts are persisted to the filesystem as Parquet (data/features), JSON (metadata/forecasts/reports), UBJ (XGBoost models), and NPY (arrays), enabling deterministic reuse across services.}
  \label{fig:system-architecture}
\end{figure}

\textbf{Key interactions:}
\begin{itemize}
  \item \textbf{FastAPI} loads trained artifacts (e.g., XGBoost boosters and JSON metadata) from the shared registry and provides REST endpoints.
  \item \textbf{Prefect Server} runs the orchestration layer (tracking flow runs, deployments, retries, and schedules).
  \item \textbf{Prefect Worker} executes the actual pipeline steps (ingestion, feature engineering, training, forecasting), writing outputs to disk.
  \item \textbf{Artifact store (filesystem):} Models and metadata are saved under \texttt{ml/registry/\textless TICKER\textgreater/\textless UTC\_TIMESTAMP\textgreater/} to support versioning and rollback.
\end{itemize}

\section{Containerization Workflow}
Thalassa uses Docker for reproducibility and Docker Compose for local multi-service orchestration.

\textbf{Containers:}
\begin{itemize}
  \item \textbf{API container:} Runs \texttt{uvicorn app.main:app} and exposes port 8000.
  \item \textbf{Prefect Server container:} Runs \texttt{prefect server start} and exposes port 4200 for UI and API.
  \item \textbf{Prefect Worker container:} Starts a Prefect worker in a named work pool (\texttt{thalassa-pool}).
  \item \textbf{Prefect init container (one-shot):} Bootstraps the work pool and registers a scheduled deployment (cron) before exiting.
\end{itemize}

\textbf{Shared volumes for artifacts:} Docker Compose mounts named volumes to ensure both the API and the worker see identical artifacts:
\begin{itemize}
  \item \texttt{ml/data} for raw data snapshots (Parquet)
  \item \texttt{ml/features} for engineered features (Parquet)
  \item \texttt{ml/registry} for model/version outputs (UBJ/JSON/NPY) and ML check reports
\end{itemize}

\begin{figure}[htbp]
  \centering
  \includegraphics[width=1.05\linewidth]{container_workflow.png}
  \caption{Containerization workflow. Docker ensures dependency and runtime consistency (Python 3.11 + ML libraries). Docker Compose coordinates multiple services and uses shared volumes so pipeline outputs are instantly available to the API without copying.}
  \label{fig:container-workflow}
\end{figure}

\subsection{External Access (ngrok)}
To facilitate development, demonstrations, and external integration testing, the system employs \texttt{ngrok} to securely tunnel local services to the public internet. This specifically exposes the FastAPI endpoints (port 8000) and optionally the Prefect UI (port 4200). This approach enables validation of end-to-end prediction routes under production-like conditions. This method provides temporary access without the security risk of permanently opening ports on the host network.

\section{CI/CD Pipeline Explanation}
The project uses GitHub Actions to enforce code quality, run tests, execute the pipeline, validate outputs, and finally build/push a Docker image.

\textbf{Pipeline stages (job ordering):}
\begin{itemize}
  \item \textbf{Linting/Formatting:} \texttt{ruff check .} and \texttt{black --check .}.
  \item \textbf{Testing:} \texttt{pytest -q} with CI-friendly tests that avoid requiring network access.
  \item \textbf{Pipeline Execution:} Runs \texttt{python tools/run\_pipeline.py} to generate artifacts.
  \item \textbf{Artifact Verification:} Confirms feature outputs exist (e.g., \texttt{ml/features/AAPL.parquet} is non-empty) and uploads produced artifacts.
  \item \textbf{DeepChecks Runner:} Executes \texttt{ml/deepchecks/run\_deepchecks.py} to check integrity, drift, and performance, uploading reports. Severe failures can gate the workflow.
  \item \textbf{Docker Build/Push:} Builds and pushes \texttt{ghcr.io/<owner>/thalassa-api:latest} to GHCR when prior stages succeed.
\end{itemize}

\begin{lstlisting}[language=bash,caption={Representative CI commands executed in GitHub Actions.}]
# Lint + formatting
ruff check .
black --check .

# Tests
pytest -q

# Pipeline
python tools/run_pipeline.py

# ML checks (gating)
python ml/deepchecks/run_deepchecks.py --features ml/features/AAPL.parquet --registry ml/registry --ticker AAPL --fail-on-severe

# Build & push image happens after checks
docker build -t ghcr.io/<owner>/thalassa-api:latest .
docker push ghcr.io/<owner>/thalassa-api:latest
\end{lstlisting}

\section{Prefect Orchestration Flow}
The Prefect flow (\texttt{flows/flow.py}) orchestrates the end-to-end pipeline with clear task boundaries and artifact persistence.

\textbf{Concrete flow order:} A single run constructs a timestamped run directory (UTC) and executes:
\begin{itemize}
  \item \textbf{Ingest:} Download price data from \texttt{yfinance} and write raw snapshots to Parquet.
  \item \textbf{Engineer:} Build time-series features (returns, rolling means/EMAs, volatility, RSI, MACD, lags) and persist features to Parquet.
  \item \textbf{Train (supervised):} Train an XGBoost regressor (next-day return) and an XGBoost classifier (next-day Up/Down) with metrics and metadata.
  \item \textbf{Train (additional analytics):} Generate association rules, compute KMeans clusters, compute PCA transformations.
  \item \textbf{Forecast:} Fit ARIMA and write forecast JSON (including confidence intervals and diagnostics).
  \item \textbf{Optional post-step:} Produce a next-day probability and label using the latest feature row (\texttt{predict\_next}).
\end{itemize}

\begin{figure}[htbp]
  \centering
  \includegraphics[width=1.02\linewidth]{prefect_flow.png}
  \caption{Prefect orchestration in Thalassa. Tasks are isolated, retryable, and produce explicit artifacts.}
  \label{fig:prefect-flow}
\end{figure}

\section{Methodology Flow}
This section describes the full data journey from raw ingestion to serving predictions through the API.

\subsection{Data ingestion (raw layer)}
The system downloads historical OHLCV market data using \texttt{yfinance}. The ingestion task includes both Prefect-level retries and internal exponential backoff attempts to handle rate limits and transient failures. The raw dataset is stored as Parquet in \texttt{ml/data/}.

\subsection{Feature engineering (feature layer)}
The pipeline constructs engineered features. Table \ref{tab:feature-lookup} provides a lookup reference for the core technical indicators used.
\begin{table}[htbp]
\caption{Feature Engineering Lookup Table}
\label{tab:feature-lookup}
\begin{center}
% Scales the table to the exact width of a single column
\resizebox{\columnwidth}{!}{%
\begin{tabular}{|l|l|p{5.5cm}|}
\hline
\textbf{Feature} & \textbf{Type} & \textbf{Description \& Purpose} \\
\hline
SMA / EMA & Trend & Simple/Exponential Moving Averages smooth price noise to reveal general direction (e.g., 30-day trend). \\
\hline
RSI & Momentum & Relative Strength Index (0--100). Measures speed of price changes. $>$70 implies overbought; $<$30 implies oversold. \\
\hline
MACD & Momentum & Measures relationship between two moving averages. Divergence signals potential trend reversals. \\
\hline
Volatility & Risk & Rolling standard deviation of returns. High values indicate chaotic/risky market regimes. \\
\hline
Lags & Memory & Past values (e.g., $t-1, t-7$) shifted to the current row. Allows the model to ``see'' history explicitly. \\
\hline
\end{tabular}%
}
\end{center}
\end{table}

These features are persisted as Parquet in \texttt{ml/features/} [7].

\subsection{Modeling (model layer)}
Supervised models train on engineered features:
\begin{itemize}
  \item Regression trains on numeric feature columns and predicts next-day returns.
  \item Classification builds labels from next-day return sign and optimizes a probabilistic objective.
\end{itemize}
The system also runs PCA/KMeans to summarize structure and regimes, and ARIMA to forecast price trajectories.

\subsection{Artifact versioning (registry layer)}
All run outputs are written under:
\texttt{ml/registry/<TICKER>/<UTC\_TIMESTAMP>/}.
This folder includes model binaries (XGBoost UBJ), metadata (JSON), arrays (NPY), and forecasting outputs (JSON). A dedicated subdirectory can store ML check reports.

\subsection{Validation gates (quality layer)}
The internal DeepChecks-style runner evaluates:
\begin{itemize}
  \item Data integrity: missingness, duplicates, and date monotonicity.
  \item Drift checks: a KS-test heuristic across numeric features (with configurable windowing).
  \item Performance checks: load latest model artifacts and score on available feature/label structure (when feasible).
\end{itemize}
Reports are stored under \texttt{ml/registry/deepchecks/} and can block CI if severe issues are detected.

\subsection{Serving (API layer)}
FastAPI exposes endpoints for health checks, triggering pipelines, prediction, classification, and forecasting. The service loads artifacts from the registry and aligns feature vectors to the model's expected feature order before inference.

\begin{figure}[htbp]
  \centering
  \includegraphics[width=1.02\linewidth]{methodology_flow.png}
  \caption{End-to-end methodology in Thalassa. The pipeline operationalizes data collection, feature engineering, training, validation, and serving into a repeatable MLOps loop, with filesystem-based artifact versioning as the system of record.}
  \label{fig:methodology-flow}
\end{figure}

\section{CONCLUSION}

\textbf{Final Observations:} This project demonstrates that a single orchestrated workflow can support multiple finance ML tasks while maintaining reproducibility through artifact versioning. For classification, probability quality is emphasized using Logloss and AUC, supplemented by calibration statistics (e.g., Brier score and calibration bins) to evaluate reliability. For regression and forecasting, the system records error summaries (RMSE/MAE) and ARIMA diagnostics (AIC/BIC), supporting transparent model comparison.

\textbf{Limitations:} The system relies on \texttt{yfinance}, which introduces fragility through potential rate limits, outages, and inconsistent symbol metadata. Furthermore, financial data is subject to non-stationarity and concept drift, meaning historical performance may not reliably translate to future market regimes. There is also a risk that tree-based learners may overfit engineered indicators without rigorous leakage controls. Finally, while ARIMA serves as a robust baseline, its simplicity may lead to underfitting when faced with complex market dynamics and volatility clustering.

\textbf{Future work:} Future iterations will prioritize \textbf{stronger validation} by adding stability metrics and improved drift detection mechanisms, such as multivariate and seasonality-aware checks. The system also aims to implement \textbf{contextual data augmentation} to automatically incorporate peer-group data and capture sector-wide correlations. Research will expand into \textbf{richer models}, exploring volatility-aware approaches and probabilistic forecasting where complexity is justified. Finally, operational improvements will focus on \textbf{registry hardening} by migrating from filesystem artifacts to a dedicated model registry with explicit promotion stages. Additionally, we plan to implement \textbf{smart caching execution}; if the registry already contains a valid, up-to-date model and dataset for a requested ticker, the system will serve the existing artifact immediately rather than triggering a redundant end-to-end pipeline run.

\section*{Acknowledgment}
I would like to expresses sincere gratitude to both the instructors for giving us a project that pushed us to learn a lot of different industry standard tools and go through the full MLOps experience in this project. Moreover, I would also like to show my gratitude the open-source contributors behind the Python ecosystem, Prefect and FastAPI. Special thanks are due to the maintainers of the \texttt{yfinance} library for making one of the best API for stocks that I know about as not only can it pull information related to any company whose ticker exists  yahoo finance, but also all the crypto currencies as well. Moreover, special thanks to the people who documented docker and CI / CD pipeline.

\begin{thebibliography}{00}

% [1] Algorithmic Trading Concepts
\bibitem{investopedia_algo}
S. Seth, ``Basics of Algorithmic Trading: Concepts and Examples,'' \textit{Investopedia}, 2024. [Online]. Available: \url{https://www.investopedia.com/articles/active-trading/101014/basics-algorithmic-trading-concepts-and-examples.asp}

% [2] Backtesting & Data Challenges
\bibitem{quantstart_backtest}
M. Halls-Moore, ``Successful Backtesting of Algorithmic Trading Strategies - Part I,'' \textit{QuantStart}, 2023. [Online]. Available: \url{https://www.quantstart.com/articles/Successful-Backtesting-of-Algorithmic-Trading-Strategies-Part-I/}

% [3] XGBoost Official Docs
\bibitem{xgboost_docs}
XGBoost Developers, ``XGBoost Documentation: Introduction to Boosted Trees,'' \textit{ReadTheDocs}, 2024. [Online]. Available: \url{https://xgboost.readthedocs.io/en/stable/tutorials/model.html}

% [4] ARIMA (Hyndman Online Guide)
\bibitem{hyndman_arima}
R. J. Hyndman and G. Athanasopoulos, ``Forecasting: Principles and Practice (3rd ed) - Chapter 9: ARIMA Models,'' \textit{OTexts}, 2021. [Online]. Available: \url{https://otexts.com/fpp3/arima.html}

% [5] Scikit-Learn Clustering/PCA
\bibitem{sklearn_guide}
Scikit-learn Developers, ``User Guide: Clustering and Decomposition,'' \textit{Scikit-learn.org}, 2024. [Online]. Available: \url{https://scikit-learn.org/stable/modules/clustering.html}

% [6] MLOps Architecture
\bibitem{google_mlops}
Google Cloud Architecture Center, ``MLOps: Continuous delivery and automation pipelines in machine learning,'' \textit{Google Cloud}, 2024. [Online]. Available: \url{https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning}

% [7] Technical Indicators
\bibitem{investopedia_tech}
J. Chen, ``Technical Indicator: Definition, Types, and Examples,'' \textit{Investopedia}, 2024. [Online]. Available: \url{https://www.investopedia.com/terms/t/technicalindicator.asp}

\end{thebibliography}

\end{document}
